version: '3.8'

services:
  inferencebot:
    build: .
    container_name: inferencebot
    restart: unless-stopped
    environment:
      - DISCORD_BOT_TOKEN=${DISCORD_BOT_TOKEN}
      - DISCORD_CLIENT_ID=${DISCORD_CLIENT_ID}
      - DISCORD_GUILD_ID=${DISCORD_GUILD_ID}
      - LLM_API_KEY=${LLM_API_KEY}
      - LLM_API_BASE=${LLM_API_BASE}
      - LLM_DEFAULT_MODEL=${LLM_DEFAULT_MODEL:-asi1-mini}
    volumes:
      - ./logs:/app/logs
    # Optional: if you need to expose a port for health checks
    # ports:
    #   - "3000:3000"
    # Resource limits (adjust as needed)
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
